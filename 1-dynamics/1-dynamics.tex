\documentclass[nols,twoside,nofonts,nobib,nohyper]{tufte-handout}

\usepackage{fixltx2e}
\usepackage{tikz-cd}
\usepackage{tcolorbox}
\usepackage{appendix}
\usepackage{listings}
\lstset{language=TeX,
       frame=single,
       basicstyle=\ttfamily,
       captionpos=b,
       tabsize=4,
  }

\input{acronyms}
\renewcommand*{\acsfont}[1]{\textsc{#1}}

\usepackage[font=footnotesize]{caption}

\makeatletter
% Paragraph indentation and separation for normal text
\renewcommand{\@tufte@reset@par}{%
  \setlength{\RaggedRightParindent}{0pt}%
  \setlength{\JustifyingParindent}{0pt}%
  \setlength{\parindent}{0pt}%
  \setlength{\parskip}{\baselineskip}%
}
\@tufte@reset@par

% Paragraph indentation and separation for marginal text
\renewcommand{\@tufte@margin@par}{%
  \setlength{\RaggedRightParindent}{0pt}%
  \setlength{\JustifyingParindent}{0pt}%
  \setlength{\parindent}{0pt}%
  \setlength{\parskip}{\baselineskip}%
}
\makeatother

\usepackage{multicol}

\setcounter{secnumdepth}{3}

% Set up the spacing using fontspec features
\renewcommand\allcapsspacing[1]{{\addfontfeature{LetterSpace=15}#1}}
\renewcommand\smallcapsspacing[1]{{\addfontfeature{LetterSpace=10}#1}}

\usepackage{amsthm}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{The dynamic turn I:\\
Update semantics}

\author[Patrick D. Elliott \& Danny Fox]{Patrick~D. Elliott \& Danny Fox}

\addbibresource[location=remote]{/home/patrl/repos/bibliography/master.bib}

\lingset{
  belowexskip=-1\baselineskip,
  aboveglftskip=0pt,
  belowglpreambleskip=0pt,
  belowpreambleskip=0pt,
  interpartskip=0pt,
  extraglskip=0pt,
  Everyex={\parskip=0pt}
}

\usepackage{float}


% \usepackage{booktabs} % book-quality tables
% \usepackage{units}    % non-stacked fractions and better unit spacing
% \usepackage{lipsum}   % filler text
% \usepackage{fancyvrb} % extended verbatim environments
%   \fvset{fontsize=\normalsize}% default font size for fancy-verbatim environments

% % Standardize command font styles and environments
% \newcommand{\doccmd}[1]{\texttt{\textbackslash#1}}% command name -- adds backslash automatically
% \newcommand{\docopt}[1]{\ensuremath{\langle}\textrm{\textit{#1}}\ensuremath{\rangle}}% optional command argument
% \newcommand{\docarg}[1]{\textrm{\textit{#1}}}% (required) command argument
% \newcommand{\docenv}[1]{\textsf{#1}}% environment name
% \newcommand{\docpkg}[1]{\texttt{#1}}% package name
% \newcommand{\doccls}[1]{\texttt{#1}}% document class name
% \newcommand{\docclsopt}[1]{\texttt{#1}}% document class option name
% \newenvironment{docspec}{\begin{quote}\noindent}{\end{quote}}% command specification environment

\begin{document}

\maketitle% this prints the handout title, author, and date

\begin{tcolorbox}
\textbf{Homework}
\tcblower
\begin{itemize}
   \item If you haven't already, please submit your solutions to \textit{last week's p-set}.
  \item You can find this week's p-set in the appendix of this handout. Please submit your work \textbf{before next week's class}. Unregistered students are also encouraged to attempt the p-set, especially since this will feed into our discussion next week.
    \item Please email this week's p-set directly to me @ \texttt{pdell@mit.edu}.
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}
\textbf{Readings}
\tcblower
This will depend on how much progress we make today. I'll send out an announcement after class.
\end{tcolorbox}

\section{Looking ahead}

\begin{description}
    \item[The dynamic turn pt 1] propositional update semantics, and its applications to presupposition projection (\citealt{Heim1983}), and epistemic modality (\citealt{Veltman1996,GroenendijkEtAl1996}).
    \item[Explanatory approaches to projection] George's (\citeyear{George2007,George2008,George2014}) \textit{middle Kleene} --- a more explanatory theory of presupposition projection and \citet{Fox2013} on quantificational sentences.
    \item[Anaphora] Anaphora in the dynamic tradition (\citealt{Heim1982,GroenendijkStokhof1991,Dekker1994}).
      and explanatory theories of anaphora (\citealt{Rothschild2017}, \citealt{Elliott2020b,Elliott2020d} and \citealt{Mandelkern2020a,Mandelkern2020b}) (n.b. very tentative!).
\end{description}

\section{Recap: trivalent semantics and Stalnaker's bridge}

The account of presupposition Danny has been outlining has the following basic ingredients.

\begin{itemize}
    \item A \enquote{gappy} semantics for sentences; this gives rise to the notion of the \textit{semantic presupposition} of a sentence.
    \item A notion of \textit{assertion}, which tells us how to update a context $c$ with the information conveyed by a sentence $ϕ$.
    \item The conditions under which update of a context $c$ with $ϕ$ is defined (\textit{Stalnaker's bridge}).
\end{itemize}

\subsection{Trivalence}

Given a non-empty \textit{set of possible worlds} $W$, a sentential meaning is a function $p:W ↦ \set{1,0,\#}$. Here's a simple example:

\ex
$\eval{Sarah's corgi is sleepy} = \begin{cases}
  1&\textsf{Sarah has a corgi} \& \textsf{Sarah's corgi is sleepy}\\
  0&\textsf{Sarah has a corgi} \& \textsf{Sarah's corgi isn't sleepy}\\
  \#&\textsf{otherwise}
  \end{cases}$
\xe

In trivalent semantics, the \textit{semantic presupposition of a sentence $S$} is the set of worlds $w$, such that $\eval{S} w$ is either true or false.\sidenote[][-10\baselineskip]{At the end of the previous handout, Danny alludes to the possibility of a principled trivalent semantics for generalized quantifiers and other expressions. We'll return to questions of projection in the sub-sentential domain once we move on to discuss explanatory approaches to presupposition projection in the following weeks.

  Since we'll begin our discussion of dynamic semantics by introducing a semantics for a toy propositional fragment, questions of sub-sentential compositionality will be put to one side in this week's material.
}

\begin{definition}[Semantic presupposition]
  $$
  ϕ^{π} ≔ \set{w | (\eval*{ϕ} w = 1) ∨ (\eval*{ϕ} w = 0)}
  $$
\end{definition}

\ex~
$(\text{Sarah's corgi is sleepy})^{π} = \set{w | \ml{Sarah has a corgi in }w}$
\xe

\subsection{Update and Stalnaker's bridge}

\begin{definition}[Stalnakerian update]
The \textit{update} induced by a a sentence $ϕ$ on a context $c$ is a partial function $c[ϕ]:\mathscr{P}(W) ↦ \mathscr{P}(W)$, defined as follows:\sidenote[][-5\baselineskip]{Note, this formulation of bridge is different to the one that Danny introduced --- but equivalent. By defining the \textit{semantic presupposition} of a sentence, we can describe Stalnaker's bridge as the requirement that the context $c$ \textit{entails} the semantic presupposition of $ϕ$. Since entailment in possible world semantics amounts to subsethood, this is equivalent to the requirement that $ϕ$ is true or false (never $\#$) at every world in $c$.

The advantage of this definition is that we can maintain Stalnaker's bridge irregardless of our assumptions concerning what kind of semantic objects \textit{semantic presuppositions} and \textit{contexts} are, just so long as we have a derivative notion of entailment.
}

$$
c[ϕ] ≔ \begin{cases}
  \set{w | w ∈ c ∧ \eval*{ϕ} w}&c ⊆ ϕ^{π}\\
  \textsf{undefined}&\textsf{otherwise}
\end{cases}
$$
\end{definition}

We say that the presuppositions of a sentence $ϕ$ are \textit{satisfied} with respect to a context $c$ if $c[ϕ]$ is defined.

Stalnakerian pragmatics allows us to define some potentially interesting notions, although their application will be limited to the level of the discourse. For example, \textit{redundancy}.

\begin{definition}[Redundancy]
  A sentence $ϕ$ is \textit{redundant} with respect to a context $c$ if (i) $c[ϕ]$ is \textit{defined} (i.e., $c ⊆ ϕ^{π}$), and (ii) $c ⊆ \set{w | \eval*{ϕ} w = 1}$.

  I.e., $ϕ$ is redundant in $c$ if $ϕ$'s presupposition is satisfied in $c$, and $c$ entails the assertive content of $ϕ$.
\end{definition}

\pex
\a It's raining. (In fact) it's raining heavily.
\a It's raining heavily. \# (In fact) it's raining.
\xe

One thing that should already give us pause is that this account of \textit{redundancy} doesn't straightforwardly generalize to conjunctive sentences (why?).

\pex
\a It's raining and (in fact) it's raining heavily.
\a\ljudge{\#}It's raining heavily and (in fact) it's raining.
\xe

\subsection{Successive update}

A (trivial?) observation: updating $c$ with a sentence $ϕ$ can make the presupposition of a sentence $ψ$ redundant, thus ensuring that $c[ψ]$ is guaranteed to be defined.

\ex
Sarah has a corgi. Sarah's corgi is sleepy.
\xe

Stalnakerian pragmatics directly captures this, since successive assertions, if accepted, induce successive update of the common ground.

We can write a successive update of $c$ with $ϕ$ followed by $ϕ'$ as $c[ϕ][\psi]$.

$$c[ϕ][ψ] ≔ (c[ϕ])[ψ]$$

Note that in the following example Stalnaker's bridge is trivially satisfied here, since $P ∩ Q ⊆ Q$. More generally, if $Q' ⊆ Q$, then $P ∩ Q' ⊆ Q$.

$$
c[\text{Sarah has a corgi}] = \overbrace{\set{w | w ∈ c ∧ \ml{Sarah has a corgi in }w}}^{c'}
$$

$$
(\text{Sarah's corgi is sleepy})^{π} ⊆ c'
$$

$$
c'[\text{Sarah's corgi is sleepy}] = \begin{cases}
  \set{w | w ∈ c' ∧ \ml{Sarah's corgi is sleepy in }w}&
    c ∩ c' ⊆ c'\\
  \ml{undefined}&\ml{otherwise}
  \end{cases}
$$

$$
c'[\text{Sarah's corgi is sleepy}] =
  \set{w | w ∈ c' ∧ \ml{Sarah's corgi is sleep in }w}
$$

Now, note that the conjunctive sentence has the same projection properties, and importantly exhibits \textit{linear asymmetries}:

\pex
\a Sarah has a corgi and her corgi is sleepy.
\a\ljudge{\#}Sarah's corgi is sleepy and she has a corgi.
\xe

\pex~
\a Sarah has a corgi. Her corgi is sleepy.
\a\ljudge{\#} Her corgi is sleepy. Sarah has a corgi.
\xe

In dynamic semantics, we'll take this intuition seriously --- the \textit{meaning} of $ϕ ∧ ψ$ will be successive assertion of $ϕ$ and $ψ$, in that order.

In our first propostitional dynamic fragment, we'll extend this notion to the other connectives.

First, a historical note...

\section{Dynamic semantics}

\subsection{Empirical motivations for dynamic semantics}

Historically, dynamic semantics --- independently developed by Irene Heim (\citeyear{Heim1982}) and Hans Kamp (\citeyear{Kamp1981}) --- was motivated by \textit{anaphora to singular indefinites}.

Briefly, pronouns can co-vary with indefinites in preceding sentences:

\pex
\a A$^{1}$ man walked in. He$_{1}$ sat down.
\a\ljudge{\#}He$_{1}$ walked in. A$^{1}$ man sat down.
\xe

More generally, pronouns can co-vary with indefinites, even when not in their scope (\textit{donkey pronouns}).

\ex Everyone [who bought a$^{1}$ new puppy during the pandemic] treasured it$_{1}$.
\xe

Both discourse and donkey anaphora are sensitive to the \text{form} of preceding sentences; not just classical content (the famous \textit{marble} example is due to Barbara Partee).

\pex
\a\ljudge{\#}I've found nine out of my ten marbles. It$_{1}$'s under the couch.\\
cf. One$^{1}$ out of my 10 marbles is lost. It$_{1}$'s under the couch.
\a\ljudge{*}Josie is married. He$_{1}$'s annoying.\\
cf. Josie has a$^{1}$ husband. He$_{1}$'s annoying.
\xe

We'll discuss the dynamic approach to anaphora invented by \citet{Heim1982} and subsequently put on firm logical foundations by \citet{GroenendijkStokhof1991} in a couple of weeks time. This will involve adopting a slightly richer notion of \textit{information states} than sets of possible worlds.

Broadly, there are two approaches to dynamics, distinguished by \citet{Yalcin2013} as follows:

\begin{description}

    \item[Dynamic representation] Sentences denote instructions for updating a particular kind of representation, which is subsequently interpreted compositionally (the DRT tradition; \citealt{Kamp1981}).

    \item[Dynamic interpretation] The compositional value of a sentence is an instruction for updating a body of information (the Heimian tradition; \citealt{Heim1982}).

\end{description}

In this class, I'll take the latter view as a given. As shown by \citet{GroenendijkStokhof1991}, the Heimian approach is in fact equivalent to the DRT approach, and \enquote{cuts out the middle man}, so to speak. It also makes the relationship to Stalnakerian pragmatics clearer.

Subsequently, the remit of dynamic semantics was expanded to encompass theories of an extremely broad range of phenomena, including amongst others:

\begin{itemize}

  \item Presupposition projection (\citealt{Heim1983,Beaver2001}, a.o.).
  \item Epistemic modality (\citealt{Veltman1996,GroenendijkEtAl1996}, a.o.).
  \item Intervention effects (\citealt{Honcoop1998}, a.o.).
  \item Conditionals (\citealt{Gillies2004}, a.o.).
  \item Generalized quantifiers and discourse plurals (\citealt{vandenBerg1996}, a.o.)
  \item Scalar implicature (\citealt{Sudo2019}, a.o.).
  \item Weak crossover (\citealt{Chierchia2020,Elliott2020b}).
  \item etc.

\end{itemize}

We'll start with presupposition projection, and subsequently, epistemic modality, since these topics only require reference to the simplest version of dynamic semantics --- update semantics on a simple propositional calculus --- and the Stalnakerian notion of content that we're already familiar with.


\subsection{Towards an update semantics}

Successive assertion patterns with \textit{conjunction} wrt presupposition projection (Danny's handout from last week; Karttunen's generalization).

A natural way of cashing this out: a conjunctive sentence, in some sense, \textit{is} a successive assertion.

\ex Conjunctive sentences in update semantics (def.)\\
$c[ϕ\text{ and }ψ] ≔ c[ϕ][ψ]$
\xe

We'll formalize this idea and extend it to the other connectives here.

\begin{displayquote}[\cite{Veltman1996}]
\enquote{The slogan `You know the meaning of a sentence if you know the conditions under which it is true', is replaced by this one: `You know the meaning of a sentence if you know the change it brings about in the information state of anyone who accepts the news conveyed by it'.}
\end{displayquote}

A (non-presuppositional) update semantics for a simple propositional language (after \citealt{Veltman1996} and \citealt{Heim1983}).\sidenote{Strangely, \citeauthor{Veltman1996} gives a symmetric semantics for conjunction his his original paper. We'll need the Heimian connectives to account for the data of interest to us here --- this was later rectified in \citet{GroenendijkEtAl1996}.}

\begin{definition}[Syntax of a simple propositional language]
  A language $\mathscr{L}$ is the smallest set, where:\sidenote{This is just a concise statement of the syntax of propositional logic.}
  \begin{itemize}
      \item $\mathscr{A} ⊆ \mathscr{L}$, where $\mathscr{A}$ is a non-empty finite set of atomic formulas $p,q,…$.
      \item if $ϕ ∈ \mathscr{L}$, then $¬ ϕ ∈ \mathscr{L}$.
      \item if $ϕ,ψ ∈ \mathscr{L}$, then $(ϕ ∧ ψ), (ϕ → ψ), (ϕ ∨ ψ) ∈ \mathscr{L}$.
  \end{itemize}
\end{definition}


\begin{definition}[Model]
A model $M$ is a pair $⟨W,I⟩$ consisting of a non-empty set of possible worlds $W$, and an evaluation function $I:\mathscr{A} ↦ \mathscr{P}(W)$ from atomic sentences of the language to subsets of $W$ (i.e., bivalent propositions/information states).
\end{definition}

\begin{definition}[Information state]
  An \textit{information state}\sidenote[][-4\baselineskip]{\citet{Veltman1996} gives an algebraic characterization of update systems which remains neutral regarding the ontology of information states themselves. Next time, we'll be consider an update system with a different notion of information state, but as we'll see, the algebraic properties of the update system will remain largely in place.} (also called a \textit{context}) is any subset of $W_{M}$. The set of possible information states is therefore $\mathscr{P}(W)$, where:
  \begin{itemize}
      \item $∅$ is the \textit{absurd information state}.
      \item $W$ is the \textit{ignorance state} (i.e., the space of logical possibilities).
  \end{itemize}
\end{definition}

N.b. the role of the \textit{absurd information state} will be the same as in Stalnakerian pragmatics. It is an idealization representing the point at which a discourse crashes.

For example, a successful update of $c$ by $p$, followed by an update of $c$ with $¬ p$ will result in the absurd information state.

\ex
It's raining. \# It's not raining.
\xe

Naturally, discourse participants will ordinarily reject an assertion that would lead to the absurd information state.

Providing a \textit{dynamic semantics} consists of recursively defining an \textit{update function} $.[.]:\mathscr{L} ↦ \mathscr{P}(W) ↦ \mathscr{P}(W)$ which maps sentences of our language to functions from information states to information states.\sidenote[][-4\baselineskip]{In fact, we only need to give a semantics for conjunctive and negated formulas. Disjunction and material implication can be defined in terms of conjunction and negation under classical equivalence:

  \begin{itemize}
      \item $ϕ ∨ ψ ≔ ¬ (¬ ϕ ∧ ¬ ψ)$
      \item $ϕ → ψ ≔ ¬ (ϕ ∧ ¬ ψ)$
  \end{itemize}

  See the first exercise in this week's problem set (the appendix) for more.
}

Think back to the slogan of dynamic semantics (taken from \citeauthor{Veltman1996}) --- the meaning of a sentence \textit{is} the effect it has on the context.

\begin{definition}[Basic expressions]
  $$
  c[p] ≔ c ∩ I(p)
  $$
  Updating a context $c$ with $p$ involves subtracting worlds from $c$ where $p$ is false. Since, at this point we're dealing with a completely bivalent semantics, we don't need to say anything about bridge; every atomic sentence is assumed to be either true or false at every point.
\end{definition}

\begin{definition}[Negated formulas]
  $$
  c[¬ \phi] ≔ c - c[\phi]
  $$
  To update a context $c$ with a negated formula $¬ ϕ$: (i) let $c' = c[ϕ]$, (ii) do $c - c'$.
\end{definition}

\begin{definition}[Conjunctive formulas]
  $$
  c[\phi ∧ \psi] ≔ c[\phi][\psi]
  $$
  To update a context $c$ with a conjunctive formula $ϕ ∧ ψ$: (i) let $c' = c[ϕ]$, (ii) do $c'[ψ]$. This is identical to successive assertion.
\end{definition}

\begin{definition}[Disjunctive formulas]
  $$
  c[\phi ∨ \psi] ≔ c[\phi] ∪ c[¬ \phi][\psi]
  $$
  To update a context $c$ with a disjunctive formula $ϕ ∨ ψ$: (i) let $c' = c[ϕ]$, let (ii) let $c'' = c[¬ ϕ]$, (iii) do $c''[ψ]$ and union the result with $c'$.
\end{definition}

\begin{definition}[Conditional formulas]
  $$
  c[ϕ → ψ] ≔ c - (c[ϕ] - c[ϕ][ψ])
  $$
  To update a context $c$ with a conditional formula $ϕ → ψ$: (i) let $c' = c[ϕ]$, (ii) let $c'' = c[ϕ][ψ]$, (iii) do $c - (c' - c'')$.
\end{definition}

We can \textit{staticize} \citeauthor{Veltman1996}'s fragment by taking the \textit{proposition expressed by $p$} to be $W[p]$, i.e., the logical space updated with $p$. $\eval*{p} ≔ W[p]$.\footnote{
As \citet{Veltman1996} remarks, since \textit{updates} are functions from information states to information states, it would probably make more sense to write $[ϕ](c)$ for the update of $c$ by $ϕ$. We'll however follow much of the existing literature by sticking to the classical $c[ϕ]$ notation, which has the advantage of making it easier to reason about successive updates ($[ψ]([ϕ](c))$ vs. the more iconic $c[ϕ][ψ]$).
}

$$
\begin{aligned}[l]
    &\eval*{p}  &= I(p)\\
    &\eval*{¬ ϕ} &= W - \eval*{ϕ}\\
    &\eval*{\phi ∧ \psi}  &= \eval*{\phi} ∩ \eval*{\psi}\\
    &\eval*{\phi ∨ \psi} &= \eval*{\phi} ∪ \eval*{\psi}\\
  \end{aligned}
$$

As an exercise in this week's problem set, i've asked you informally prove the above equivalences.

Some important logical properties of update semantics:

\begin{description}
    \item[Eliminativity] For any sentence $ϕ$, $c[ϕ] ⊆ c$.
    \item[Distributivity] For any sentence $ϕ$, $c[ϕ] = \bigcup\limits_{w ∈ c}(\set{w}[ϕ])$
\end{description}

\begin{itemize}

    \item Informally, eliminativity says that updating an information state $c$ with $ϕ$ always results in either (a) a stronger information state, or (b) the absurd state. This ensures that updates can't \textit{remove} information.

    \item Distributivity says that updating a context $c$ with $ϕ$ is equivalent to updating each world $w ∈ c$ with $ϕ$, and gathering up the results. This ensures that the result of an update is only ever sensitive to properties of individual points, rather than the context as a whole. This is an important constraint on update semantics.

\end{itemize}

We won't go into this in detail here, but \citet{Benthem1986} famously proves that any dynamic semantics that is \textit{eliminative} and \textit{distributive} admits of a static reformulation; in other words, for any sentence $ϕ$, we can model $c[ϕ]$ as $c ∩ \eval{ϕ}$.\sidenote{See \cite{RothschildYalcin2016,RothschildYalcin2017} for detailed discussion of this point.}

As we modify the fragment to account for presupposition and epistemic modals, we'll see ways in which eliminativity and distributivity fail.\sidenote{Concretely, distributivity will fail once we discuss epistemic modals. Eliminativity will fail when we come round to discussing anaphora.}

Before doing so, it's worth noting that even the simplest, bivalent formulation of propositional update semantics allows us to formulate a notion of \textit{redundancy} which will do some empirical work.

Informally, a sentence $ϕ$ is redundant in $c$ if the result of computing some derivative update $c'[ψ]$ is redundant.

\pex
\a It's raining and (in fact) it's raining heavily.
\a\ljudge{\#}It's raining heavily and (in fact) it's raining.
\xe

\pex~
\a If it's raining then it's raining heavily.
\aljudge{\#}If it's raining heavily then it's raining.
\xe

We won't be discussing \textit{redundancy} in depth in this class, but I'll finish this section by noting an interesting problem uncovered by \citet{MayrRomoli2016}:

\ex
Either Paul isn't married or he is (married) and he lives in London.
\xe

As noted by \citeauthor{MayrRomoli2016}, the logical form of the sentence is $⌜¬ ϕ ∨ (ϕ ∧ ψ)$. If we apply the recipes for the logical connectives in dynamic semantics, we predict the following update:

$$
c[¬ ϕ ∨ (ϕ ∧ ψ)] = c[¬ ϕ] ∪ c[¬ ¬ ϕ][ϕ][ψ]
$$

\citet{MayrRomoli2016} present a fairly involved solution, which we won't go into here. See also Sudo (under revision) for a solution which makes use of a stricter notion of redundancy, framed in terms of situation semantics.

\subsection{Update semantics and presupposition projection}

\citet{Heim1983} was the first to demonstrate that update semantics can account for the Karttunen-Peters projection generalizations.

First we need to supplement our update semantics with presuppositions.

\begin{definition}[Model with trivalence]
A model $M$ is a pair $⟨W,I⟩$ consisting of a non-empty set of possible worlds $W$, and a valuation function $I:\mathscr{A} ↦ F$, where $F$ is the set of total mappings $f:W ↦ \set{1,0,\#}$ from worlds to (trivalent) truth-values.
\end{definition}

We only need to change the definition of our basic update operation to incorporate Stalnaker's bridge.

\begin{definition}[Basic expressions (partial semantics)]
  $$
  c[p] ≔ \begin{cases}
    c ∩ \set{w| I(p)(w) = 1}&∀w' ∈ c[I(p)(w') = 1 ∨ I(p)(w') = 0]\\
    \text{undefined}&\text{otherwise}
    \end{cases}
  $$
\end{definition}

Treating the update induced by an atomic sentence as a \textit{partial} function imbues the entire logic with a notion of presupposition.

The difference between the approach here, and a classical trivalent semantics is that, due to the incremental nature of updates induced by complex sentences, the definedness conditions on update can be satisfied locally.

\pex
\a $\overbrace{\text{Sarah stopped smoking}}^{p}$
\a $I(p) = λ w . \begin{cases}
  1&\text{Sarah smoked in }w\text{ and doesn't smoke in }w\\
  0&\text{Sarah smoked in }w\text{ and still smokes in }w\\
  \#&\text{otherwise}
  \end{cases}$
\xe

Equivalently:

\ex
$I(p) = λ w . \begin{cases}
  \text{defined}&\text{Sarah smoked in }w\\
  \text{true}&\text{Sarah doesn't smoke in }w
  \end{cases}$
\xe

As before, the semantic presupposition of a sentence $p$, $p^{π}$ is the set of worlds in which $I(p)$ is defined.

We can use this abbreviation to simplify our update rule further:

\begin{definition}[Basic expression (revised)]
  $$
  c[p] ≔ \begin{cases}
    c ∩ \set{w| I(p)(w) = 1}&c ⊆ p^{π}\\
    \text{undefined}&\text{otherwise}
    \end{cases}
  $$
\end{definition}

Let's go through a concrete concrete case, in $w_{cy}$ Sarah has a corgi and it's cute, in $w_{cn}$  Sarah has a corgi and it's not cute, and in $w_{∅}$ Sarah has no corgi. Recall also the rule for conditional statements.

 $$
  c[ϕ → ψ] ≔ c - (c[ϕ] - c[ϕ][ψ])
  $$

\ex
If Sarah has a corgi, then Sarah's corgi is cute.\\
$p → q$, where $I(p) = q^{π}$
\xe

\begin{itemize}
    \item $\set{w_{cy},w_{cn},w_{∅}}[p → q]$\\$= \set{w_{cy},w_{cn},w_{∅}} - (\set{w_{cy},w_{cn},w_{∅}}[p] - \set{w_{cy},w_{cn},w_{∅}}[p][q])$
    \item $ = \set{w_{cy},w_{cn},w_{∅}} - (\set{w_{cy},w_{cn}} - \set{w_{cy},w_{cn},w_{∅}}[p][q])$
    \item $ = \set{w_{cy},w_{cn},w_{∅}} - (\set{w_{cy},w_{cn}} - \set{w_{cy},w_{cn}}[q])$
    \item $\set{w_{cy},w_{cn}}[q]$ is defined, since $\set{w_{cy},w_{cn}} = q^{π}$
    \item $ = \set{w_{cy},w_{cn},w_{∅}} - (\set{w_{cy},w_{cn}} - \set{w_{cy}})$
    \item $ = \set{w_{cy},w_{∅}}$
\end{itemize}

Anoother concrete case, this time involving disjunction, using the same set of worlds:

$$
c[ϕ ∨ ψ] ≔ c[ϕ] ∪ c[¬ ϕ][ψ]
$$

\ex
Either Sarah has no corgi, or Sarah's corgi is cute.\\
$¬ p ∨ q$, where $q^{π} = \set{w_{cy},w_{cn}}$
\xe

\begin{itemize}
    \item $\set{w_{cy},w_{cn},w_{∅}}[¬ p ∨ q] = \set{w_{cy},w_{cn},w_{∅}}[¬ p] ∪ \set{w_{cy},w_{cn},w_{∅}}[¬ ¬ p][q]$
    \item $= \set{w_{∅}} ∪ (\set{w_{cy},w_{cn},w_{∅}} - (\set{w_{cy},w_{cn},w_{∅}} - \set{w_{cy},w_{cn}}))[q]$
    \item $= \set{w_{∅}} ∪ \set{w_{cy},w_{cn}}[q]$\footnote{Note that double-negation elimination is valid in propositional update semantics.}
    \item N.b. the update of $q$ is guaranteed to be defined, since $\set{w_{cy},w_{cn}} = q^{π}$
    \item $= \set{w_{∅}} ∪ \set{w_{cy}}$
    \item $= \set{w_{∅},c_{cy}}$
\end{itemize}

Update semantics gives rise to the following generalization for presupposition:

\begin{definition}[Presupposition satisfaction] The presupposition of  $ϕ$ is satisfied in $c$, if the following hold:

  \begin{itemize}
      \item $c \subseteq p^{π}$, if $ϕ = p$
    \item The presupposition of $ψ$ is satisfied in $c$,\\
      if $ϕ = (¬ ψ)$.
    \item The presupposition of $ψ$ is satisfied in $c$\\
      and the presupposition of $χ$ is satisfied in $c[ψ]$,\\
      if $ϕ = (ψ ∧ χ)$.
    \item The presupposition of $ψ$ is satisfied in $c$,\\
      and the presupposition of $χ$ is satisfied in $c[¬ ψ]$\\
      if $ϕ = (ψ ∨ χ)$.
    \item The presupposition of $ψ$ is satisfied in $c$,\\
      and the presupposition of $χ$ is satisfied in $c[ψ]$\\
      if $ϕ = (ψ → χ)$.
  \end{itemize}

\end{definition}

Note that the proviso problem still lurks in the background here (\citealt{Geurts1996}).\sidenote{In fact, the proviso problem was originally discussed as a problem for dynamic accounts of presupposition projection specifically. It has subsequently been recognized that the proviso problem afflicts static trivalent theories too -- we'll discuss this more in future classes.} Consider the following worlds: $w_{hc}$ Sarah is here and has a cute corgi, $w_{c}$ Sarah isn't here but has a cute corgi, $w_{h}$ Sarah is here but has no corgi, $w_{∅}$ Sarah isn't here and doesn't have a cute corgi.

\ex
If Sarah is here, then Sarah's corgi is cute.\\
$p → q$
\xe

\begin{itemize}
  \item $\set{w_{hc},w_{c},w_{h},w_{∅}}[p → q]$\\
    $ = \set{w_{hc},w_{c},w_{h},w_{∅}} - (\set{w_{hc},w_{h}} - \set{w_{hc},w_{c},w_{h},w_{∅}}[p][q])$
    \item $\set{w_{hc},w_{c},w_{h},w_{∅}} - (\set{w_{hc},w_{h}} - \set{w_{hc},w_{h}}[q])$
    \item $\set{w_{hc},w_{h}}[q]$ is undefined since $\set{w_{hc},w_{h}} ⊈ q^{π}$
    \item How could we minimally modify the context such that the presupposition is satisfied? We can simply remove the world in which Sarah is here, and doesn't have a corgi.
    \item $\set{w_{hc},w_{c},w_{∅}}[p → q] = \set{w_{hc},w_{c},w_{∅}} - (\set{w_{hc}} - \set{w_{hc},w_{c},w_{∅}}[p][q])$
    \item $= \set{w_{hc},w_{c},w_{∅}} - (\set{w_{hc}} - \set{w_{hc}}[q])$
    \item $\set{w_{hc}}[q]$ is defined, since $\set{w_{wc}} \subseteq q^{π}$
    \item $= \set{w_{hc},w_{c},w_{∅}}$
  \item Predicted inference:
    \begin{itemize}
        \item If Sarah is here, then Sarah has a corgi.
        \item Equivalently, either Sarah isn't here, or she has a corgi.
    \end{itemize}
  \item The attested inference seems stronger, namely, \textit{Sarah has a corgi}.
\end{itemize}

There are various ways of tweaking the theory to account for proviso cases, requiring a more or less radical departure from standard update semantics: see e.g., \cite{Mandelkern2016} and \cite{Grove2019,Grove2019a} for two recent approaches.

It's worth emphasizing that this is a problem specifically for the theory of \textit{accommodation} --- since we're just interested in presupposition projection here, we'll put this problem to one side.


\subsection{The Rooth-Soames objection}

We now have a theory that successfully accounts for Karttunen's projection generalizations. Should we be satisfied?

\citet{Heim1983} assumed that the classical semantics for the logical connectives \textit{fully determined} the formulation of the update rules.

This was subsequently noted to be incorrect by Mats Rooth, p.c. to Irene Heim in 1987, as well as \cite{Soames1989}; a result that has motivated much recent work on presupposition projection.\sidenote{This relates to Danny's objection to using higher-order functions to capture presupposition projection.}

The most straightforward way of demonstrating this by defining an update rule for \textit{backwards conjunction} ($⩟$).

\begin{definition}[Update rule for backwards conjunction]
  $$
  c[ϕ \wedgebar ψ] ≔ c[ψ][ϕ]
  $$
\end{definition}

Backwards conjunction presumably isn't plausibly lexicalized in natural language, and it certainly doesn't characterize the meaning of \textit{and}.

Otherwise, we'd predict the following sentence to be presuppositionless, contrary to fact:

\ex
Josie's sister met her in London, and Josie has a sister.
\xe

Nevertheless, staticizing backwards conjunction gives us...\textit{logical conjunction}:\sidenote{Because set intersection is a symmetric operation.}

$$
\eval*{ϕ \wedgebar ψ} ≔ W[ψ][ϕ] = \eval*{ϕ} ∩ \eval*{ψ} ≕ \eval*{ϕ ∧ ψ}
$$

What this shows is that, even though there's a unique mapping from an update semantics to the corresponding classical semantics (i.e., \citeauthor{Veltman1996}'s \textit{staticization}), there are many possible mappings from classical semantics to the corresponding update semantics.

As an exercise in this weeks problem set, I've asked you to define other \enquote{deviant} connectives.

What does this mean for update semantics as an \textit{explanation} for presupposition projection?

I think it's wrong to conclude that this makes the account \textit{completely} stipulative/non-explanatory in character.\sidenote{Danny may disagree here!}

\begin{itemize}

    \item On the basis of a relatively small set of stipulations, update semantics delivers predictions for an infinite number of sentences.

    \item We can't really escape from stipulating the classical semantics that update semantics extends.

\end{itemize}

The objection is narrower, but simultaneously perhaps more interesting.


It looks like what we're doing is simply tailoring the definitions of the connectives to capture Karttunen's projection generalizations.

But, we have the hunch that it's no accident that the dynamic semantics of natural language conjunction is forwards conjunction $∧$ and not backwards conjunction $\wedgebar$. One way of answering the objection would be to develop a principled story for why we converge upon this update rule rather than some other concievable update rule that is truth-conditionally adequate.

In other words, if we have a predictive algorithm for update rules, or something similar, perhaps we can get away with generating the same set of predictions as \citeauthor{Heim1983}'s update semantics with fewer stipulations.

A big question in the current literature on presupposition projection is how exactly to accomplish this. A non-exhaustive list of references includes \cite{George2007,George2008,George2014}, \cite{Schlenker2008,Schlenker2009,Schlenker2010}, and \cite{Fox2013}.

In future classes, we plan to discuss \citeauthor{George2007}'s \textit{middle Kleene} algorithm in this light.\sidenote{If we have time, i'll also discuss my own work on developing a predictive theory of anaphora using similar technical machinery (\citealt{Elliott2020b}), as well as \citeauthor{Mandelkern2020a}'s recent (\citeyear{Mandelkern2020a,Mandelkern2020b}) work on this topic.}

Another answer to this objection is as follows: dynamic semantics, and specifically \textit{these} dynamic connectives capture other phenomena too. The most famous example of such a phenomena is \textit{anaphora}. A competing theory will only be more explanatory if it has the same empirical coverage.

Here, we'll discuss another such phenomena that dynamic semantics has been used to capture: epistemic modals and epistemic contradictions.\sidenote{In \cite{Veltman1996}, update semantics is also applied to cases of so-called \enquote{default reasoning}, i.e.:

  \pex
\a P's are normally R.
\a $x$ is P.
\a Presumably, $x$ is R.
\xe

We won't cover this topic in this class, but I encourage those of you interested in reading further to do so.
}

\subsection{\citeauthor{Veltman1996}'s test semantics and epistemic contradictions}

% \todo[inline]{Remember to talk about pragmatic view and Yalcin's response}

\begin{displayquote}[\cite{Beaver2001}]
  \enquote{I will borrow from Veltman’s work to show how the context sensitivity of [epistemic modal] words like `might' and `must' motivates a dynamic semantics. None of the alternative CCPs for connectives
that have been suggested by Rooth and Soames would be compatible with this semantics, and it is hard to imagine how a relevantly different dynamic semantics could still get the facts right about the meanings of the epistemic modalities.}
\end{displayquote}

An initial motivation for a dynamic treatment of epistemic modality: epistemic contradictions and order sensitivity.\sidenote{Discussion of such \textit{epistemic contradictions} has a long history in the philosophy of language literature, going back to \cite{Moore1942}.}

\pex\label{moore}
\a\ljudge{?}It might be raining, but it's not raining.\label{moore1}
\a\ljudge{\#}It's not raining, but it might be raining.\label{moore2}
\xe

Do we need to go beyond a classical semantics for modals to explain the oddness of (\ref{moore})? Let's tentatively assume that an assertion of \enquote{it might be raining} is true if \textit{it's raining} is compatible with the speaker's knowledge.

An argument against a pragmatic story: \citeauthor{Yalcin2007}'s (\citeyear{Yalcin2007}) embedded cases:

\pex
\a\ljudge{?}Suppose that [it might be raining but it's not raining].
\a\ljudge{?}Suppose that [it's not raining but it might be raining].
\xe

Difficult to see how a pragmatic explanation might extend to such cases.

As originally demonstrated by \citet{Veltman1996}, it's possible to state an elegant semantics for epistemic modality in update semantics that captures the oddness of epistemic contradictions.

We'll extend our simple propositional language with an additional unary operator, standing in for \textit{might}: $◇$.

\begin{definition}[Test semantics for epistemic possibility]
  $$
  c[◇ \phi] ≔ \begin{cases}
    c&c[\phi] ≠ ∅\\
    ∅&\text{otherwise}
    \end{cases}
  $$
\end{definition}

\begin{tcolorbox}
  \textbf{The intuition}
  \tcblower
  An assertion of \enquote{it might be raining} is a prompt to \textit{tentatively} update the context set $c$ with the information \textit{it's raining}. If the update is successful (i.e., if it doesn't result in the absurd information state), simply return $c$ unchanged.
\end{tcolorbox}

\begin{tcolorbox}
  \textbf{Discussion point}
  \tcblower
  According to \citeauthor{Veltman1996}'s theory, when we assert a modalized sentence one of two things can happen: (i) if the test is successful, the context is unchanged. (ii) if the test is unsuccessful, we find ourselves in the absurd state.

  Why would we ever \textit{use} epistemic modals?
\end{tcolorbox}

Although \citeauthor{Veltman1996} doesn't do so, it's possible to define epistemic \textit{must} ($□$) as the dual of $◇$ is propositional update semantics. One of the exercises in his week's problem set is to do just this.

To show how this captures asymmetries in epistemic contradictions, first we will need some derivative notions.

\begin{definition}[Consistency]
A sentence $ϕ$ is consistent with respect to $c$, if $c[ϕ] ≠ ∅$; a sentence $ϕ$ is \textit{consistent} simpliciter, if there is some information state $c'$, s.t., $c'[ϕ]$ is consistent.
\end{definition}

\enquote{It's raining and it's not raining} is \textit{inconsistent}, since there is no information state $c$, such that updating $c$ with this sentence will result in a non-absurd information state. This holds for all classical contradictions.

Concretely, if $\eval*{ϕ} = ∅$, then $ϕ$ is inconsistent.

Let's return to one of the examples that motivated a dynamic semantics for epistemic modality.

\ex
It's not raining outside, but it might be raining outside.\\
$¬ p ∧ ◇ p$\label{moore2}
\xe

A good result: (\ref{moore2}) is \textit{inconsistent}.

Before giving an informal proof, the intuition is as follows: updating an information state with the information that it's not raining is guaranteed to make a tentative update of \enquote{it's raining} fail.

\ex
It's not raining and it might be raining.
\xe

\begin{itemize}

    \item $c[¬ p ∧ ◇ p] = c[¬ p][◇ p]$
    \item $= (c - I(p))[◇ p]$
  \item $= \begin{cases}
    c - I(p)&(c - I(p)[p] ≠ ∅\\
    ∅&\text{otherwise}
    \end{cases}$
  \item $= \begin{cases}
    c - I(p)&((c - I(p) ∩ I(p)) ≠ ∅\\
    ∅&\text{otherwise}
    \end{cases}$
  \item $(c - s) ∩ s = ∅$, $∀s$, hence $(¬ p ∧ ◇ p)$ is \textit{inconsistent}.
\end{itemize}

What about the other ordering, repeated in (\ref{moore-rep})? Although we didn't assign this a $\#$ diacritic, arguably there is something pragmatically marked about this sentence.

\ex
\ljudge{?}It might be raining and it's not raining.\\
$◇ p ∧ ¬ p$\label{moore-rep}
\xe

In fact, we can construct variations of (\ref{moore-rep}) which sound more natural:

\ex
A: It might be raining.\\
B: It's not raining!
\xe

\ex
It might be raining [...] it's not raining.
\xe

We can make sense of this in update semantics by using the notion of \textit{coherence}, which we define in terms of a derivative notion of \textit{support}.

\begin{definition}[Support]
  An information state $c$ \textit{supports} a sentence $ϕ$ iff:

  $$c[ϕ] = c$$

  Other terms which are often used to mean the same thing: \textit{$c$ accepts $\phi$, $c$ incorporates $\phi$, $ϕ$ is redundant in $c$}.
\end{definition}

\begin{definition}[Coherence]
$ϕ$ is coherent iff there is some non-absurd information state $c$, s.t., $c$ \textit{supports} $ϕ$.
\end{definition }

Note that \textit{coherence} implies \textit{consistency}: if a non-absurd $c$ supports $ϕ$, then $c[ϕ]$ is consistent, and hence $ϕ$ is consistent simpliciter.

Now we can ask ourselves, is (\ref{moore-rep}) consistent/coherent?

\begin{itemize}
    \item $c[◇ p ∧ ¬ p] = c[◇ p][¬ p]$
  \item $= \begin{cases}
    c[¬ p]&c[p] ≠ ∅\\
    ∅[¬ p]&\text{otherwise}
   \end{cases}$
  \item $= \begin{cases}
    c - c[p]&c[p] ≠ ∅\\
    ∅&\text{otherwise}
    \end{cases}$
\end{itemize}

(\ref{moore-rep}) is \textit{consistent}, since as long as both $p$ and $¬ p$ are $c$-consistent, then updating $c$ with (\ref{moore-rep}) will result in a non-absurd information state --- namely, one that supports $¬ p$.

Now can can ask, is (\ref{moore-rep}) \textit{coherent}? The answer is no. For the test imposed by $◇ p$ to be successful in $c$, $c$ cannot support $¬ p$, and for $c$ to support $p ∧ q$, $c[p]$ must support $q$.\sidenote{A sketch of a proof by contradiction:

  \begin{itemize}
      \item If $◇ p ∧ ¬ p$ is coherent; there exists a $c$, s.t., $c[◇ p ∧ ¬ p] = c$.
    \item If $c[◇ p ∧ ¬ p] = c$,\\
      then $(c[◇ p])[¬ p] = c$,\\
      so by eliminativity $c[◇ p] = c[¬ p] = c$
    \item if $c[◇ p] = c$, then $c[p] ≠ ∅$
    \item if $c[p] ≠ ∅$, then $c - p ≠ c$
      \item Therefore $c[¬ p] ≠ c$
  \end{itemize}

}

\begin{tcolorbox}
  \textbf{Optional exericse}
  \tcblower
Recall that, due to presupposition projection facts, the update rule for disjunctive sentences is as follows:
$$
c[ϕ ∨ ψ] ≔ c[ϕ] ∪ c[¬ ϕ][ψ]
$$
What does the theory predict for a sentence such as \enquote{either it's raining, or it might be raining}?

$$
p ∨ ◇ p
$$

What about the reverse order, \enquote{it might be raining, or it's raining}?

$$
 p ∨ ◇ p
$$

Try to connect the results to your intuitions about what these sentences mean.
\end{tcolorbox}

\printbibliography

\begin{appendices}

  \section{Problem set (due before Friday 2 October)}

  \subsection{Dynamic semantics and classical equivalence}

  In today's handout, we stated a dynamic semantics for negated sentences, conjunctive and disjunctive sentences, as well as material implications.

  In fact, the only primitives we need are a dynamic semantics for negated and conjunctive sentences. We can define disjunction and material implication via classical equivalence, but not just any classical equivalences will do.

  \begin{tcolorbox}
    \textbf{Exercise}
    \tcblower

    \textbf{Part 1:} Informally prove the following equivalences:
    \begin{itemize}
        \item $c[ϕ ∨ ψ] ≡ c[¬ (¬ ϕ ∧ ¬ ψ)]$
        \item $c[ϕ → ψ] ≡ c[¬ (ϕ ∧ ¬ ψ)]$
    \end{itemize}

    \textbf{Part 2:} Provide formulas using only conjunction and negation that are classically equivalent to $⌜ϕ ∨ ψ⌝$, $⌜ϕ→ψ⌝$, which nevertheless aren't equivalent in propositional dynamic semantics. Demonstrate where the equivalence breaks down.

    \textbf{Part 3:} Comment briefly on what this tells us about the explanatory potential of propositional dynamic semantics.
  \end{tcolorbox}

  \subsection{Staticization}

  As noted in today's handout, we can \textit{staticize} a (bivalent) propositional update semantics by taking the \textit{proposition expressed by $p$} to be $W[p]$, i.e., the logical space updated with $p$. $\eval*{p} ≔ W[p]$.

  \begin{tcolorbox}
    \textbf{Exercise}
    \tcblower
    \textbf{Part 1:} Prove whether the following equivalences (an informal demonstration is fine).

  $$
  \begin{aligned}[l]
    &\eval*{p}  &= I(p)\\
    &\eval*{¬ ϕ} &= W - \eval*{ϕ}\\
    &\eval*{\phi ∧ \psi}  &= \eval*{\phi} ∩ \eval*{\psi}\\
    &\eval*{\phi ∨ \psi} &= \eval*{\phi} ∪ \eval*{\psi}\\
    &\eval*{\phi → \psi} &= \eval*{\phi} ⊆ \eval*{\psi}\\
  \end{aligned}
  $$

  \textbf{Part 2:} What is the staticization of a modalized sentence $⌜◇ ϕ⌝$? Comment on the significance of the result.
  \end{tcolorbox}

  \subsection{Backwards connectives}

  \begin{tcolorbox}
    \textbf{Exercise}
    \tcblower
    \textbf{Part 1:} give a dynamic semantics for \enquote{backwards disjunction} $⊻$, which (i) captures the classical contribution of disjunction (demonstrate this via staticization), and (ii) predicts the presupposition of the first disjunct to be satisfied in the following (provided without judgement).

    \enquote{Either Sarah's corgi is sleepy, or Sarah has no corgi.}

    Is this prediction good, in the general case? Feel free to use raw data from whichever language(s) you speak in the discussion here.

    \textbf{Part 2:} do the same thing for \eqnuote{backwards implication}, $←$, with respect to the following sentence:

    \enquote{If Sarah's corgi is sleepy, then Sarah has a corgi.}
  \end{tcolorbox}

  \subsection{\textit{Must}}

\begin{tcolorbox}
  \textbf{Exercise}
  \tcblower
  Can we state the meaning of epistemic \textit{must} ($□$) as the dual of Veltmann's $◇$?
  \begin{itemize}
    \item If so, demonstrate that this delivers intuitively correct results.
    \item If not, show why not.
  \end{itemize}

\end{tcolorbox}


\end{appendices}

\end{document}

\end{appendices}
